# Assignment 4 (self-assigned) - Facial Expression Classification

## Contribution
The code in this assignment was developed by myself. The dataset was provided by MahmoudiMA on Kaggle.

## Description of assignment
In this self-assigned assignment, the goal is to train a Convolutional Neural Network (CNN) model to recognize human facial expressions.

## Data
The dataset used for this assignment can be found on Kaggle, [here](https://www.kaggle.com/datasets/mahmoudima/mma-facial-expression). The dataset contains three directories: training, validation, and test. Each directory consists of seven sub-directories corresponding to seven facial expression categories.

## Methods
- The `load_images_and_labels` function is used to load images and their corresponding labels from the given directory.
- The images are preprocessed by normalizing the pixel values and reshaping the image arrays.
- A Convolutional Neural Network (CNN) model is built using the TensorFlow Keras API.
- The model is trained on the training data and validated on the validation data.
- The trained model is saved for future use into the "models" folder.
- A classification report is generated by evaluating the model on the test data and saved as a text file in the "reports" folder.
- The learning curve of the model is plotted and saved as an image in the "plots" folder.

## Usage and Reproducibility

### Prerequisites
To run the code, you need Python 3  installed. Additionally, the following packages are required:
- cv2
- numpy
- pandas
- scikit-learn
- tensorflow
- PIL
- matplotlib

After cloning this GitHub repository to your own device, you can install the required packages by navigating to the root folder and running the following command in your terminal: `pip install -r requirements.txt`

### Running the scripts
- To train and evaluate the full version of the model, execute `python3 src/clf_CNN.py` in the terminal.
- To train and evaluate a smaller version of the model using only 1% of the total data, execute `python3 src/clf_CNN_lite.py` in the terminal.

## Discussion of Results
The training of the model took much longer than planned due to the large dataset, and not getting access to a machine on uCloud with high computation power. Therefore I was forced to improvise and train the model on a much smaller subset of the data. With this in mind, a visual inspection of the learning curve indicates potential overfitting, as the training loss continues to decrease over time, while the validation loss decreases slightly first and then starts to increase. This behavior could of course be attributed to the limited amount of data used for training.
